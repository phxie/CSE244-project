{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba27758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial_intelligence': 0,\n",
       " 'computer_architecture': 1,\n",
       " 'computer_networks': 2,\n",
       " 'computer_vision': 3,\n",
       " 'databases': 4,\n",
       " 'machine_learning': 5,\n",
       " 'nlp': 6,\n",
       " 'prog_languages': 7,\n",
       " 'security': 8}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"artificial_intelligence\": 0,\n",
    " \"computer_architecture\": 1, \n",
    " \"computer_networks\": 2, \n",
    " \"computer_vision\": 3, \n",
    " \"databases\": 4, \n",
    " \"machine_learning\": 5, \n",
    " \"nlp\": 6, \n",
    " \"prog_languages\": 7, \n",
    " \"security\": 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677d6eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Downloading torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0.0->accelerate)\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from torch>=2.0.0->accelerate)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xuedo\\onedrive\\desktop\\cse244-project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.6/12.0 MB 13.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/12.0 MB 15.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.0 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 16.0 MB/s  0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 19.0 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 17.1 MB/s  0:00:00\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl (453 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-win_amd64.whl (28.0 MB)\n",
      "   ---------------------------------------- 0.0/28.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 3.4/28.0 MB 15.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.8/28.0 MB 15.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 10.5/28.0 MB 16.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.6/28.0 MB 16.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 17.0/28.0 MB 16.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.4/28.0 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.6/28.0 MB 16.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.0/28.0 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.0/28.0 MB 15.7 MB/s  0:00:01\n",
      "Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading torch-2.9.1-cp312-cp312-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 3.7/110.9 MB 18.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 6.8/110.9 MB 16.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 10.2/110.9 MB 16.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 12.6/110.9 MB 15.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 16.0/110.9 MB 15.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 19.4/110.9 MB 15.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 22.8/110.9 MB 15.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 26.0/110.9 MB 16.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 29.4/110.9 MB 15.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 33.0/110.9 MB 16.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 35.9/110.9 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 39.3/110.9 MB 16.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 42.5/110.9 MB 16.0 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 45.9/110.9 MB 16.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 48.8/110.9 MB 16.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 50.9/110.9 MB 15.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 50.9/110.9 MB 15.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 53.0/110.9 MB 14.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 54.8/110.9 MB 14.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 58.2/110.9 MB 14.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 61.6/110.9 MB 14.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 65.3/110.9 MB 14.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 68.7/110.9 MB 14.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 72.6/110.9 MB 14.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 77.1/110.9 MB 15.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 81.3/110.9 MB 15.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 84.7/110.9 MB 15.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 88.1/110.9 MB 15.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 92.3/110.9 MB 15.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 96.7/110.9 MB 15.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 100.9/110.9 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 104.9/110.9 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  108.5/110.9 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 15.8 MB/s  0:00:07\n",
      "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 19.2 MB/s  0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.9/6.3 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 18.4 MB/s  0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 8.6 MB/s  0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 15.2 MB/s  0:00:00\n",
      "Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Installing collected packages: mpmath, xxhash, urllib3, typing-extensions, tqdm, sympy, setuptools, safetensors, regex, pyarrow, propcache, networkx, multidict, MarkupSafe, idna, h11, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, multiprocess, jinja2, httpcore, anyio, aiosignal, torch, huggingface-hub, httpx, aiohttp, tokenizers, accelerate, transformers, datasets, evaluate\n",
      "\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   ----------------------------------------  0/40 [mpmath]\n",
      "   -- -------------------------------------  2/40 [urllib3]\n",
      "   -- -------------------------------------  2/40 [urllib3]\n",
      "   --- ------------------------------------  3/40 [typing-extensions]\n",
      "   ---- -----------------------------------  4/40 [tqdm]\n",
      "   ---- -----------------------------------  4/40 [tqdm]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ----- ----------------------------------  5/40 [sympy]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   ------ ---------------------------------  6/40 [setuptools]\n",
      "   -------- -------------------------------  8/40 [regex]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   --------- ------------------------------  9/40 [pyarrow]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   ----------- ---------------------------- 11/40 [networkx]\n",
      "   -------------- ------------------------- 14/40 [idna]\n",
      "   --------------- ------------------------ 15/40 [h11]\n",
      "   ---------------- ----------------------- 16/40 [fsspec]\n",
      "   ---------------- ----------------------- 16/40 [fsspec]\n",
      "   ---------------- ----------------------- 16/40 [fsspec]\n",
      "   ---------------- ----------------------- 16/40 [fsspec]\n",
      "   ---------------- ----------------------- 16/40 [fsspec]\n",
      "   ------------------- -------------------- 19/40 [dill]\n",
      "   ------------------- -------------------- 19/40 [dill]\n",
      "   ------------------- -------------------- 19/40 [dill]\n",
      "   ------------------- -------------------- 19/40 [dill]\n",
      "   -------------------- ------------------- 20/40 [charset_normalizer]\n",
      "   ---------------------- ----------------- 22/40 [attrs]\n",
      "   ---------------------- ----------------- 22/40 [attrs]\n",
      "   ------------------------ --------------- 24/40 [yarl]\n",
      "   ------------------------- -------------- 25/40 [requests]\n",
      "   -------------------------- ------------- 26/40 [multiprocess]\n",
      "   -------------------------- ------------- 26/40 [multiprocess]\n",
      "   -------------------------- ------------- 26/40 [multiprocess]\n",
      "   --------------------------- ------------ 27/40 [jinja2]\n",
      "   --------------------------- ------------ 27/40 [jinja2]\n",
      "   ---------------------------- ----------- 28/40 [httpcore]\n",
      "   ---------------------------- ----------- 28/40 [httpcore]\n",
      "   ---------------------------- ----------- 28/40 [httpcore]\n",
      "   ----------------------------- ---------- 29/40 [anyio]\n",
      "   ----------------------------- ---------- 29/40 [anyio]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   ------------------------------- -------- 31/40 [torch]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   -------------------------------- ------- 32/40 [huggingface-hub]\n",
      "   --------------------------------- ------ 33/40 [httpx]\n",
      "   --------------------------------- ------ 33/40 [httpx]\n",
      "   ---------------------------------- ----- 34/40 [aiohttp]\n",
      "   ---------------------------------- ----- 34/40 [aiohttp]\n",
      "   ---------------------------------- ----- 34/40 [aiohttp]\n",
      "   ---------------------------------- ----- 34/40 [aiohttp]\n",
      "   ---------------------------------- ----- 34/40 [aiohttp]\n",
      "   ----------------------------------- ---- 35/40 [tokenizers]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------ --- 36/40 [accelerate]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   ------------------------------------- -- 37/40 [transformers]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   -------------------------------------- - 38/40 [datasets]\n",
      "   ---------------------------------------  39/40 [evaluate]\n",
      "   ---------------------------------------  39/40 [evaluate]\n",
      "   ---------------------------------------- 40/40 [evaluate]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 datasets-4.4.1 dill-0.4.0 evaluate-0.4.6 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6 propcache-0.4.1 pyarrow-22.0.0 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 setuptools-80.9.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 typing-extensions-4.15.0 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99ba352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 13, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def split_jsonl(input_file,\n",
    "                train_file=\"train.jsonl\",\n",
    "                valid_file=\"valid.jsonl\",\n",
    "                test_file=\"test.jsonl\",\n",
    "                ratios=(0.8, 0.1, 0.1),\n",
    "                seed=42):\n",
    "    \"\"\"\n",
    "    Split a single JSONL file into train/valid/test files.\n",
    "    ratios must sum to 1.0 (otherwise they'll be normalized).\n",
    "    Returns a tuple with the counts (train, valid, test).\n",
    "    \"\"\"\n",
    "    # normalize ratios\n",
    "    total = sum(ratios)\n",
    "    if total <= 0:\n",
    "        raise ValueError(\"ratios must sum to a positive number\")\n",
    "    r = [x / total for x in ratios]\n",
    "\n",
    "    p = Path(input_file)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"{input_file} not found\")\n",
    "\n",
    "    # read all non-empty lines (preserve original JSON lines)\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [ln.rstrip(\"\\n\") for ln in f if ln.strip()]\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(lines)\n",
    "\n",
    "    n = len(lines)\n",
    "    n_train = int(n * r[0])\n",
    "    n_valid = int(n * r[1])\n",
    "\n",
    "    train_lines = lines[:n_train]\n",
    "    valid_lines = lines[n_train:n_train + n_valid]\n",
    "    test_lines = lines[n_train + n_valid:]\n",
    "\n",
    "    # write out files (ensure trailing newline if non-empty)\n",
    "    def write_lines(path, arr):\n",
    "        path = Path(path)\n",
    "        if arr:\n",
    "            path.write_text(\"\\n\".join(arr) + \"\\n\", encoding=\"utf-8\")\n",
    "        else:\n",
    "            # create empty file\n",
    "            path.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "    write_lines(train_file, train_lines)\n",
    "    write_lines(valid_file, valid_lines)\n",
    "    write_lines(test_file, test_lines)\n",
    "\n",
    "    return (len(train_lines), len(valid_lines), len(test_lines))\n",
    "\n",
    "# Example usage:\n",
    "split_jsonl(\"dataset.jsonl\", \"train.jsonl\", \"valid.jsonl\", \"test.jsonl\", ratios=(0.8,0.1,0.1), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8877f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 108 examples [00:00, 14595.93 examples/s]\n",
      "Generating validation split: 13 examples [00:00, 2164.33 examples/s]\n",
      "Generating test split: 14 examples [00:00, 2332.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": \"train.jsonl\",\n",
    "                                           \"validation\": \"valid.jsonl\",\n",
    "                                           \"test\": \"test.jsonl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8020a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"],\n",
    "                     padding=\"max_length\",\n",
    "                     truncation=True,\n",
    "                     max_length=512)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "# tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "tokenized.set_format(\"torch\",\n",
    "                     columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7678ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'artificial_intelligence': 0, 'computer_architecture': 1, 'computer_networks': 2, 'computer_vision': 3, 'databases': 4, 'machine_learning': 5, 'nlp': 6, 'prog_languages': 7, 'security': 8}\n"
     ]
    }
   ],
   "source": [
    "# Build a deterministic mapping from string labels to integers and apply it to `tokenized`\n",
    "unique_labels = set()\n",
    "for split in tokenized:\n",
    "    unique_labels.update(set(tokenized[split][\"label\"]))\n",
    "\n",
    "label_list = sorted(unique_labels)  # deterministic order\n",
    "label2id = {lab: i for i, lab in enumerate(label_list)}\n",
    "\n",
    "def _map_label(example):\n",
    "    lab = example[\"label\"]\n",
    "    # if already integer, keep as is\n",
    "    if isinstance(lab, int):\n",
    "        return example\n",
    "    example[\"label\"] = label2id[lab]\n",
    "    return example\n",
    "\n",
    "tokenized = tokenized.map(_map_label)\n",
    "\n",
    "# ensure torch format (re-apply to be safe)\n",
    "tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# update num_labels variable\n",
    "num_labels = len(label2id)\n",
    "\n",
    "print(\"label2id:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2be47e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'prog_languages': 15, 'nlp': 14, 'computer_networks': 14, 'security': 12, 'computer_vision': 12, 'artificial_intelligence': 11, 'machine_learning': 11, 'databases': 10, 'computer_architecture': 9})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(dataset[\"train\"][\"label\"])\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94063709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label torch.int64\n",
      "input_ids torch.int64\n",
      "attention_mask torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(tokenized[\"train\"]))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de039990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# num_labels = 1\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"allenai/scibert_scivocab_uncased\",\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9dcc9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_out\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4d7ed864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "000c3080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 11:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.607599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.437704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.324036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>1.263627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>1.261231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=70, training_loss=0.40813522338867186, metrics={'train_runtime': 706.3584, 'train_samples_per_second': 0.764, 'train_steps_per_second': 0.099, 'total_flos': 142088899645440.0, 'train_loss': 0.40813522338867186, 'epoch': 5.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ff54428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.289337158203125,\n",
       " 'eval_runtime': 2.6917,\n",
       " 'eval_samples_per_second': 5.201,\n",
       " 'eval_steps_per_second': 0.372,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b29c75d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuedo\\OneDrive\\Desktop\\CSE244-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.425}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "preds = trainer.predict(tokenized[\"test\"])\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "y_true = preds.label_ids\n",
    "\n",
    "acc = accuracy.compute(predictions=y_pred, references=y_true)\n",
    "print(acc)\n",
    "\n",
    "f1 = evaluate.load(\"f1\")\n",
    "preds = trainer.predict(tokenized[\"test\"])\n",
    "f1_score = f1.compute(predictions=preds.predictions.argmax(-1),\n",
    "                      references=preds.label_ids,\n",
    "                      average=\"macro\")\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "042c2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('final_model\\\\tokenizer_config.json',\n",
       " 'final_model\\\\special_tokens_map.json',\n",
       " 'final_model\\\\vocab.txt',\n",
       " 'final_model\\\\added_tokens.json',\n",
       " 'final_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"final_model\")\n",
    "tokenizer.save_pretrained(\"final_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
